## Topics Discussed VT 2022

__Week 7 (Feb 16)__
_- Host:_ Amanda

*This Looks Like That: Deep Learning for Interpretable Image Recognition*
<br>
Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, Jonathan K. Su
<br>
https://papers.nips.cc/paper/2019/hash/adf7ee2dcf142b0e11888e72b43fcb75-Abstract.html

__Week 9 (Mar 2)__
_- Host:_ Filip

*Generative Modeling by Estimating Gradients of the Data Distribution*
<br>
Yang Song, Stefano Ermon
<br>
https://arxiv.org/abs/1907.05600

__Week 11 (Mar 16)__
_- Host:_ Fredrik

*Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation*
<br>
Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, Yoshua Bengio
<br>
https://papers.nips.cc/paper/2021/hash/e614f646836aaed9f89ce58e837e2310-Abstract.html

*Some related papers:*
<br>
* [GFlowNet Foundations paper](https://arxiv.org/abs/2111.09266) Yoshua Bengio, Tristan Deleu, Edward J. Hu, Salem Lahlou, Mo Tiwari, Emmanuel Bengio, "GFlowNet Foundations", arXiv:2111.09266, November 2021.
  * A longer paper introducing the model, underlying theory and various extensions

* [Trajectory Balance paper](https://arxiv.org/abs/2201.13259) Nikolay Malkin, Moksh Jain, Emmanuel Bengio, Chen Sun, Yoshua Bengio, “Trajectory Balance: Improved Credit Assignment in GFlowNets", arXiv:2201.13259, January 2022.
  * Here they introduce a more efficient training objective for the model.

* [Energy-Based GFlowNet paper](https://arxiv.org/abs/2202.01361) Dinghuai Zhang, Nikolay Malkin, Zhen Liu, Alexandra Volokhova, Aaron Courville, Yoshua Bengio, “Generative Flow Networks for Discrete Probabilistic Modeling", arXiv:2202.01361, February 2022.
  * Here they show how the GFlowNet model can be combined with an EBM to learn the energy function/target distribution from data. They also discuss how to build an efficient MCMC proposal for discrete spaces using the learnt GFlowNet.

* [Causal Graph Bayesian Posterior paper](https://arxiv.org/abs/2202.13903) Tristan Deleu, António Góis, Chris Emezue, Mansi Rankawat, Simon Lacoste-Julien, Stefan Bauer, Yoshua Bengio, “Bayesian Structure Learning with Generative Flow Networks", arXiv:2202.13903, February 2022.
  * Here they use the method for learning a Bayesian network

__Week 13 (Mar 30)__
_- Host:_ Josef

*Dangers of Bayesian Model Averaging under Covariate Shift*
<br>
Pavel Izmailov, Patrick Nicholson, Sanae Lotfi, Andrew G. Wilson
<br>
https://proceedings.neurips.cc/paper/2021/hash/1ab60b5e8bd4eac8a7537abb5936aadc-Abstract.html \+ Supplemental

Our rating : 3.17 ± 0.37

*Some related papers:*

* [What are bayesian neural network posteriors really like?](https://proceedings.mlr.press/v139/izmailov21a.html) Details on HMC sampling of the posterior in the main paper can be found here.
* Priors for Bayesian neural networks:
  * [Bayesian Neural Network Priors Revisited](https://arxiv.org/abs/2102.06571)
  * [Priors in Bayesian Deep Learning: A Review](https://arxiv.org/abs/2105.06868)
* Some background on covariate shift/domain shift:
  * [Domain Adaptation for Statistical Classifiers](https://www.jair.org/index.php/jair/article/view/10454)
  * [Out of Distribution Generalization in Machine Learning](https://arxiv.org/abs/2103.02667)
  * [Benchmarking Neural Network Robustness to Common Corruptions and Perturbations](https://arxiv.org/abs/1903.12261)


__Week 15 (Apr 13)__
_- Host:_ Joel

*The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process*
<br>
Hongyuan Mei, Jason Eisner
<br>
https://arxiv.org/abs/1612.09328

Our rating : 3.00 ± 0.53

*Some related papers:*
  * [Neural Jump Stochastic Differential Equations](https://arxiv.org/abs/1905.10403)
  * [Neural Spatio-Temporal Point Processes](https://arxiv.org/abs/2011.04583)

__Week 17 (Apr 27)__
_- Host:_ Per

*Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts*
<br>
Bertrand Charpentier, Daniel Zügner, Stephan Günnemann
<br>
https://proceedings.neurips.cc/paper/2020/hash/0eac690d7059a8de4b48e90f14510391-Abstract.html

Our rating : 3.57 ± 0.49

*Some related papers:*
  * [Predictive Uncertainty Estimation via Prior Networks](https://proceedings.neurips.cc/paper/2018/hash/3ea2db50e62ceefceaf70a9d9a56a6f4-Abstract.html)
  * [Natural Posterior Network: Deep Bayesian Uncertainty for Exponential Family Distributions](https://arxiv.org/abs/2105.04471)

__Week 19 (May 11)__
_- Host:_ Anton

*Spatio-Temporal Variational Gaussian Processes*
<br>
Oliver Hamelijnck, William Wilkinson, Niki Loppi, Arno Solin, Theodoros Damoulas
<br>
https://proceedings.neurips.cc/paper/2021/hash/c6b8c8d762da15fa8dbbdfb6baf9e260-Abstract.html

__Week 21 (May 25)__
_- Host:_ Magnus

*A Simple Baseline for Bayesian Uncertainty in Deep Learning*
<br>
Wesley J. Maddox, Pavel Izmailov, Timur Garipov, Dmitry P. Vetrov, Andrew Gordon Wilson
<br>
https://proceedings.neurips.cc/paper/2019/hash/118921efba23fc329e6560b27861f0c2-Abstract.html

Our rating : 2.25 ± 0.43

__Week 23 (Jun 8)__
_- Host:_ Hariprasath

*Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results*
<br>
Antti Tarvainen, Harri Valpola
<br>
https://papers.nips.cc/paper/2017/hash/68053af2923e00204c3ca7c6a3150cf7-Abstract.html

*Some related papers:*
  * [Temporal Ensembling for Semi-Supervised Learning](https://arxiv.org/pdf/1610.02242.pdf)
  * [Dual Student: Breaking the Limits of the Teacher in Semi-supervised Learning
](https://openaccess.thecvf.com/content_ICCV_2019/papers/Ke_Dual_Student_Breaking_the_Limits_of_the_Teacher_in_Semi-Supervised_ICCV_2019_paper.pdf)

Our rating : 2.75 ± 0.43

__Week 25 (Jun 22)__
_- Host:_ Amirhossein

*Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization*
<br>
Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, Percy Liang
<br>
https://arxiv.org/abs/1911.08731

Our rating : 3.00 ± 0.58


