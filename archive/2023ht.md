## Topics Discussed HT 2023

__Week 37 (Sep 13)__
<br>
__Guest: Søren Hauberg__

*On Masked Pre-training and the Marginal Likelihood*
<br>
Pablo Moreno-Muñoz, Pol G. Recasens, Søren Hauberg
<br>
https://arxiv.org/abs/2306.00520

__Week 39 (Sep 27)__
<br>
__Topic: Generative flow networks__
_- Host:_ Dong

*Learning GFlowNets from partial episodes for improved convergence and stability*
<br>
Kanika Madan, Jarrid Rector-Brooks, Maksym Korablyov, Emmanuel Bengio, Moksh Jain, Andrei Nica, Tom Bosc, Yoshua Bengio, Nikolay Malkin
<br>
https://arxiv.org/abs/2209.12782

*Related papers:*

* Emmanuel Bengio et al. [Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation.](https://arxiv.org/abs/2106.04399) NeurIPS, 2021. (Introduction of flow-matching)
* Yoshua Bengio et al. [GFlowNet Foundations.](https://www.jmlr.org/papers/v24/22-0364.html) JMLR, 2023. (Introduction of detailed-balance)
* Nikolay Malkin et al. [Trajectory Balance: Improved Credit Assignment in GFlowNets.](https://arxiv.org/abs/2201.13259) NeurIPS, 2022. (Introduction of trajectory-balance)

Our rating: 3.00 ± 0.00

__Week 41 (Oct 11)__
<br>
__Topic: Generative flow networks__
_- Host:_ Dong

*Unifying Generative Models with GFlowNets and Beyond*
<br>
Dinghuai Zhang, Ricky T. Q. Chen, Nikolay Malkin, Yoshua Bengio
<br>
https://arxiv.org/abs/2209.02606

Our rating: 1.80 ± 0.75

__Week 43 (Oct 25)__
<br>
__Topic: Diffusion models__
_- Host:_ Filip, Amanda

*High-Resolution Image Synthesis With Latent Diffusion Models*
<br>
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer
<br>
https://openaccess.thecvf.com/content/CVPR2022/html/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.html

Our rating: 3.13 ± 0.33

__Week 45 (Nov 8)__
<br>
__Guest: Brooks Paige__

*Score-Based Diffusion meets Annealed Importance Sampling*
<br>
Arnaud Doucet, Will Grathwohl, Alexander G. Matthews, Heiko Strathmann
<br>
https://proceedings.neurips.cc/paper_files/paper/2022/hash/86b7128efa3950df7c0f6c0342e6dcc1-Abstract-Conference.html

Our rating: 2.71 ± 0.45

__Week 47 (Nov 22)__
<br>
__Topic: Diffusion models__
_- Host:_ Filip, Amanda

*Improving Diffusion Models for Inverse Problems using Manifold Constraints*
<br>
Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, Jong Chul Ye
<br>
https://proceedings.neurips.cc/paper_files/paper/2022/hash/a48e5877c7bf86a513950ab23b360498-Abstract-Conference.html

Our rating: 2.40 ± 1.02

__Week 49 (Dec 6)__
<br>
__Topic: Did Schmidhuber invent it?__
_- Host:_ Joel, Hoda

*Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks*
<br>
Jürgen Schmidhuber

*Related:*

* Jürgen Schmidhuber [Neural nets learn to program neural nets with fast weights—the first Transformer variants](https://people.idsia.ch/~juergen/fast-weight-programmer-1991-transformer.html), 2021 (Blog post)
* Vaswani, Ashish, et al. [Attention is all you need](https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html), NeurIPS 2017.

__Week 51 (Dec 20)__
<br>
__Topic: Did Schmidhuber invent it?__
_- Host:_ Joel, Hoda

*Generative Adversarial Networks are Special Cases of Artificial Curiosity (1990) and also Closely Related to Predictability Minimization (1991)*
<br>
Jürgen Schmidhuber
<br>
https://arxiv.org/abs/1906.04493

*Related:*

* Goodfellow et al. [Generative Adversarial Nets](https://proceedings.neurips.cc/paper_files/paper/2014/hash/5ca3e9b122f61f8f06494c97b1afccf3-Abstract.html), NeurIPS, 2014.
* Jürgen Schmidhuber. [Learning factorial codes by predictability minimization](https://mediatum.ub.tum.de/node?id=813184), Neural Computation, 1992.
* Jürgen Schmidhuber. [Making the world differentiable: On using fully recurrent self-supervised
neural networks for dynamic reinforcement learning and planning in non-stationary
environments](http://people.idsia.ch/~juergen/FKI-126-90_(revised)bw_ocr.pdf), Technical report, 1990.
